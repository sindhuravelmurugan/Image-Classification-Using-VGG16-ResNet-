# Image-Classification-Using-VGG16-ResNet-

## ğŸ“Œ Project Overview  
This project focuses on **image classification** using **VGG and ResNet architectures** on a dataset containing **three categories: Dogs, Food, and Vehicles**, all equally distributed.  

The goal was to explore **advanced techniques** to improve model performance, including **weight initialization, optimizers, batch sizes, regularization, and augmentation techniques**.

ğŸ”¹ **Due to academic policies, the source code is not publicly available.**  
ğŸ”¹ **However, this repository provides insights into the approach, methods, and results.**  

---

## ğŸ“‚ Dataset  
- The dataset consists of **three balanced classes: Dogs, Food, and Vehicles**.  
- Standard **preprocessing techniques** such as **image resizing, normalization, and data augmentation** were applied.  

---

## ğŸ› ï¸ Tech Stack  
- **Deep Learning Framework:** PyTorch / TensorFlow  
- **Architectures Used:** VGG16 & ResNet18  
- **Libraries Used:**  
  - `Torchvision` â€“ Pretrained models & image transformations  
  - `Matplotlib & Seaborn` â€“ Data visualization  
  - `Numpy & Pandas` â€“ Data handling  
  - `scikit-learn` â€“ Performance evaluation  

---

## ğŸ” Model Training & Optimization  

### **1ï¸âƒ£ VGG Model Architecture & Optimization**  
- Implemented **VGG16** with modifications.  
- Used **two weight initialization techniques:**  
  âœ… **He Initialization** â€“ Worked best  
  âœ… **Xavier Initialization**  
- Tested **multiple optimizers:**  
  âœ… **SGD**  
  âœ… **Adam**  
  âœ… **RMSprop**  
- Experimented with **batch sizes (16, 32)** for performance tuning.  
- Applied **regularization techniques:**  
  âœ… Early Stopping  
  âœ… K-Fold Cross Validation  
  âœ… Data Augmentation  

### **2ï¸âƒ£ ResNet Model Architecture & Optimization**  
- Implemented **ResNet18** for comparison with VGG.  
- Used **Adam Optimizer** and **Cross-Entropy Loss Function**.  
- Improved model by:  
  âœ… Testing **different batch sizes (16, 32)**  
  âœ… Using **Kaiming Weight Initialization**  
  âœ… Applying **Early Stopping**  
  âœ… Integrating **Learning Rate Scheduling (LRS)**  

---

## ğŸ“Š Results & Key Takeaways  

### **Model Accuracy Comparison for VGG16 (Different Optimizations)**  
| Optimization Method | Accuracy |
|---------------------|----------|
| Xavier Weight Initialization | 92.56% |
| He Initialization, Adam Optimizer, Batch Size = 32 | 94.02% |
| He with SGD Optimizer | 89.42% |
| He with RMS Optimizer | 92.24% |
| He (Batch Size = 16) | 90.51% |
| He with Early Stopping | 93.33% |
| He with k-Fold Cross Validation | 90.58% |
| He with Data Augmentation | 90.09% |

### **ResNet18 vs. Improved ResNet18 Model Accuracy**  
| Model | Accuracy |
|------------|----------|
| ResNet18 | 94.13% |
| Improved ResNet18 | 93.93% |

ğŸ”¹ **VGG with He Initialization and Adam Optimizer performed best at 94.02%.**  
ğŸ”¹ **ResNet18 had high accuracy (94.13%) but the improved version performed slightly lower at 93.93%.**  
ğŸ”¹ **Regularization techniques like Early Stopping and LRS improved training stability.**  

---

## ğŸš€ How to Use This Project  
ğŸš« **Due to school regulations, the source code is not publicly available.**  
ğŸ”¹ However, if you are interested in discussing this project or its methodology, feel free to reach out!  

---

## ğŸ“Œ Future Improvements  
- ğŸ”¹ Explore **transfer learning** with deeper architectures like ResNet50 or EfficientNet.  
- ğŸ”¹ Implement **semi-supervised learning** to improve performance on unseen data.  
- ğŸ”¹ Deploy a **web-based image classifier** using Flask or FastAPI.  

---

## ğŸ“œ License  
This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.  

---

## ğŸ”— Connect with Me  
ğŸ“§ Email: sindhuravel@gmail.com 
ğŸ”— LinkedIn: [Sindhura Velmurugan](https://www.linkedin.com/in/sindhura-velmurugan/)  

---

### â­ If you find this project interesting, feel free to **star** this repository!
